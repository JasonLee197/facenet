arguments: C:/Users/wesley/Google drive/Sync/19 spring/CSE 691/project/facenet/src/train_softmax.py
--------------------
tensorflow version: 1.7.0
--------------------
git hash: b'3c114cdee5a5d15e7655982a08fee33d35929c60'
--------------------
b'diff --git a/src/models/inception_resnet_v1.py b/src/models/inception_resnet_v1.py\nindex b09a767..2f1aef2 100644\n--- a/src/models/inception_resnet_v1.py\n+++ b/src/models/inception_resnet_v1.py\n@@ -20,10 +20,7 @@ As described in http://arxiv.org/abs/1602.07261.\n   Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi\n """\n \n-\'\'\'\n-Please check out the essay mentioned above for the architecture of this model.\n-Figure 10 to Figure 15\n-\'\'\'\n+\n \n from __future__ import absolute_import\n from __future__ import division\ndiff --git a/src/train_softmax.py b/src/train_softmax.py\nindex 1bfcb28..ac713a5 100644\n--- a/src/train_softmax.py\n+++ b/src/train_softmax.py\n@@ -272,7 +272,7 @@ def main(args):\n \n                 print(\'Saving statistics\')\n                 with h5py.File(stat_file_name, \'w\') as f:\n-                    for key, value in stat.iteritems():\n+                    for key, value in stat.items():\n                         f.create_dataset(key, data=value)\n \n     return model_dir\n@@ -519,27 +519,27 @@ def parse_arguments(argv):\n     parser = argparse.ArgumentParser()\n \n     parser.add_argument(\'--logs_base_dir\', type=str,\n-                        help=\'Directory where to write event logs.\', default=\'~/logs/facenet\')\n+                        help=\'Directory where to write event logs.\', default=\'C:/Users/wesley/Google drive/Sync/19 spring/CSE 691/project/facenet/output/log/facenet\')\n     parser.add_argument(\'--models_base_dir\', type=str,\n-                        help=\'Directory where to write trained models and checkpoints.\', default=\'~/models/facenet\')\n+                        help=\'Directory where to write trained models and checkpoints.\', default=\'C:/Users/wesley/Google drive/Sync/19 spring/CSE 691/project/facenet/output/models/facenet\')\n     parser.add_argument(\'--gpu_memory_fraction\', type=float,\n-                        help=\'Upper bound on the amount of GPU memory that will be used by the process.\', default=1.0)\n+                        help=\'Upper bound on the amount of GPU memory that will be used by the process.\', default=0.9)#########\n     parser.add_argument(\'--pretrained_model\', type=str,\n                         help=\'Load a pretrained model before training starts.\')\n     parser.add_argument(\'--data_dir\', type=str,\n                         help=\'Path to the data directory containing aligned face patches.\',\n-                        default=\'~/datasets/casia/casia_maxpy_mtcnnalign_182_160\')\n+                        default=\'G:/train/train\')\n     parser.add_argument(\'--model_def\', type=str,\n                         help=\'Model definition. Points to a module containing the definition of the inference graph.\',\n                         default=\'models.inception_resnet_v1\')\n     parser.add_argument(\'--max_nrof_epochs\', type=int,\n-                        help=\'Number of epochs to run.\', default=500)\n+                        help=\'Number of epochs to run.\', default=2)##############\n     parser.add_argument(\'--batch_size\', type=int,\n                         help=\'Number of images to process in a batch.\', default=90)\n     parser.add_argument(\'--image_size\', type=int,\n                         help=\'Image size (height, width) in pixels.\', default=160)\n     parser.add_argument(\'--epoch_size\', type=int,\n-                        help=\'Number of batches per epoch.\', default=1000)\n+                        help=\'Number of batches per epoch.\', default=1000)################\n     parser.add_argument(\'--embedding_size\', type=int,\n                         help=\'Dimensionality of the embedding.\', default=128)\n     parser.add_argument(\'--random_crop\',\ndiff --git a/util/plot_learning_curves.m b/util/plot_learning_curves.m\nindex ec3518a..3cd7fd4 100644\n--- a/util/plot_learning_curves.m\n+++ b/util/plot_learning_curves.m\n@@ -37,7 +37,7 @@ res = { ...\n \n %%\n res = { ...\n-{ \'20200421-105928\', \'casia, wd=5e-4, pnlf=5e-4, fixed image standardization\' }, ... % \'20200421-105928\'\xca\xc7\xce\xc4\xbc\xfe\xbc\xd0\xc3\xfb\xb3\xc6\n+{ \'20200421-195732\', \'casia, wd=5e-4, pnlf=5e-4, fixed image standardization\' }, ... % \'20200421-105928\'\xca\xc7\xce\xc4\xbc\xfe\xbc\xd0\xc3\xfb\xb3\xc6\n };\n \n %%\n@@ -106,26 +106,27 @@ for i=1:length(res),\n end;\n \n timestr = datestr(now,\'yyyymmdd_HHMMSS\');\n-\n-h = 1; figure(h); close(h); figure(h); hold on; %%setsize(1.5);\n-title(\'LFW accuracy\');\n-xlabel(\'Steps\');\n-ylabel(\'Accuracy\');\n-grid on;\n-N = 1; flt = ones(1,N)/N;\n-for i=1:length(var),\n-    plot(var{i}.epochs*1000, filter(flt, 1, var{i}.lfw_accuracy(var{i}.epochs)), lineStyles2{i}, \'LineWidth\', lineWidth);\n-end;\n-legend(legends_accuracy,\'Location\',\'SouthEast\',\'FontSize\',fontSize);\n-v=axis;\n-v(3:4) = [ 0.95 1.0 ];\n-axis(v);\n-accuracy_file_name = sprintf(\'lfw_accuracy_%s\',timestr);\n-%print(accuracy_file_name,\'-dpng\')\n-\n-\n+%%\n+if 0\n+    h = 1; figure(h); close(h); figure(h); hold on; %%setsize(1.5);\n+    title(\'LFW accuracy\');\n+    xlabel(\'Steps\');\n+    ylabel(\'Accuracy\');\n+    grid on;\n+    N = 1; flt = ones(1,N)/N;\n+    for i=1:length(var),\n+        plot(var{i}.epochs*1000, filter(flt, 1, var{i}.lfw_accuracy(var{i}.epochs)), lineStyles2{i}, \'LineWidth\', lineWidth);\n+    end;\n+    legend(legends_accuracy,\'Location\',\'SouthEast\',\'FontSize\',fontSize);\n+    v=axis;\n+    v(3:4) = [ 0.95 1.0 ];\n+    axis(v);\n+    accuracy_file_name = sprintf(\'lfw_accuracy_%s\',timestr);\n+    %print(accuracy_file_name,\'-dpng\')\n+end\n+%%\n if 1 %0\xce\xaa\xb2\xbbplot\xa3\xac1\xce\xaaplot\n-    %%\n+\n     h = 2; figure(h); close(h); figure(h); hold on; %setsize(1.5);\n     %h = 1; figure(h); hold on;\n     title(\'LFW validation rate\');\n@@ -142,9 +143,9 @@ if 1 %0\xce\xaa\n     valrate_file_name = sprintf(\'lfw_valrate_%s\',timestr);\n %    print(valrate_file_name,\'-dpng\')\n end\n-\n-if 1\n     %% Plot cross-entropy loss\n+if 1\n+\n     h = 3; figure(h); close(h); figure(h); hold on; %setsize(1.5);\n     title(\'Training/validation set cross-entropy loss\');\n     xlabel(\'Step\');\n@@ -170,9 +171,9 @@ if 1\n     xent_file_name = sprintf(\'xent_%s\',timestr);\n     %print(xent_file_name,\'-dpng\')\n end\n-\n-if 1\n     %% Plot accuracy on training set\n+if 1\n+\n     h = 32; figure(h); clf; hold on; \n     title(\'Training/validation set accuracy\');\n     xlabel(\'Step\');\n@@ -198,9 +199,9 @@ if 1\n     acc_file_name = sprintf(\'accuracy_%s\',timestr);\n     %print(acc_file_name,\'-dpng\')\n end\n-\n-if 1\n     %% Plot prelogits CDF\n+if 0\n+\n     h = 35; figure(h); clf; hold on; \n     title(\'Prelogits histogram\');\n     xlabel(\'Epoch\');\n@@ -216,9 +217,9 @@ if 1\n     legend(legends, \'Location\', \'SouthEast\',\'FontSize\',fontSize);\n     hold off\n end\n-\n-if 1\n     %% Plot prelogits norm\n+if 1\n+\n     h = 32; figure(h); clf; hold on; \n     title(\'Prelogits norm\');\n     xlabel(\'Step\');\n@@ -231,9 +232,9 @@ if 1\n     legend(legends, \'Location\', \'NorthEast\',\'FontSize\',fontSize);\n     hold off\n end\n-\n-if 1\n     %% Plot learning rate\n+if 1\n+\n     h = 42; figure(h); clf; hold on; \n     title(\'Learning rate\');\n     xlabel(\'Step\');\n@@ -246,9 +247,9 @@ if 1\n     legend(legends, \'Location\', \'NorthEast\',\'FontSize\',fontSize);\n     hold off\n end\n-\n-if 1\n     %% Plot center loss\n+if 1\n+\n     h = 9; figure(h); close(h); figure(h); hold on; %setsize(1.5);\n     title(\'Center loss\');\n     xlabel(\'Epochs\');\n@@ -264,9 +265,9 @@ if 1\n     end;\n     legend(legends, \'Location\', \'NorthEast\',\'FontSize\',fontSize);\n end\n-\n-if 1\n     %% Plot center loss with factor\n+if 1\n+\n     h = 9; figure(h); close(h); figure(h); hold on; %setsize(1.5);\n     title(\'Center loss with factor\');\n     xlabel(\'Epochs\');\n@@ -282,9 +283,9 @@ if 1\n     end;\n     legend(legends, \'Location\', \'NorthEast\',\'FontSize\',fontSize);\n end\n-\n-if 1\n     %% Plot total loss\n+if 1\n+\n     h = 4; figure(h); close(h); figure(h); hold on; %setsize(1.5);\n     title(\'Total loss\');\n     xlabel(\'Epochs\');\n@@ -297,9 +298,9 @@ if 1\n     end;\n     legend(legends, \'Location\', \'NorthEast\',\'FontSize\',fontSize);\n end\n-\n-if 1\n     %% Plot regularization loss\n+if 1\n+\n     h = 5; figure(h); close(h); figure(h); hold on; %setsize(1.5);\n     title(\'Regularization loss\');\n     xlabel(\'Epochs\');\ndiff --git a/util/readlogs.m b/util/readlogs.m\nindex 154bf61..ed6ff94 100644\n--- a/util/readlogs.m\n+++ b/util/readlogs.m\n@@ -1,7 +1,6 @@\n function [vars] = readlogs(filename,titles)\n for ii=1:length(titles)\n-    varname=string(titles(ii))\n-    h5read(filename,strcat(\'/\',string(titles(ii))))\n+    varname=string(titles(ii));\n     vars.(varname)=h5read(filename,strcat(\'/\',string(titles(ii))));\n     \n end'